# Pentest Automation Platform: Static Analysis Report

Generated: 2025-11-22

This report details findings from a static analysis of the provided workflow, database, and infrastructure-as-code artifacts. The analysis covers security vulnerabilities, code quality, workflow logic, and infrastructure misconfigurations.

## Executive Summary

The platform demonstrates sophisticated automation capabilities, particularly in cloud and credential testing. However, the analysis uncovered several critical and high-severity vulnerabilities that require immediate attention. The most severe issues include **Command Injection**, **SQL Injection**, and **insecure file permissions** within the Docker container. There is also a significant discrepancy between the documented architecture (AI-driven) and the implemented workflow logic (hardcoded).

### Overall Risk Score: CRITICAL

| Severity | Count |
| :--- | :--- |
| **CRITICAL** | 3 |
| **HIGH** | 4 |
| **MEDIUM** | 3 |
| **LOW** | 2 |
| **TOTAL** | 12 |

---

## CRITICAL Vulnerabilities

### 1. Command Injection in `credential_tester.json`
- **Severity**: `CRITICAL`
- **Location**: `credential_tester.json` -> `Build Test Command` & `Execute Test` nodes
- **Description**: The workflow constructs shell commands by directly concatenating user-controllable data from the database (`username`, `domain`, `ip_address`, `hostname`). An attacker who can control these values (e.g., by poisoning host data that is later used in a test) can execute arbitrary commands on the n8n host machine.
- **Example Vulnerable Code** (`Build Test Command` node):
  ```javascript
  // The 'target' and 'username' variables are taken directly from the database
  // and placed into a shell command string without sanitization.
  command = `timeout 10 sshpass -p 'PLACEHOLDER' ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 ${test.username}@${target} -p ${port} 'echo SUCCESS' 2>&1`;
  ```
- **Impact**: Remote Code Execution (RCE) on the n8n container, allowing a full compromise of the automation engine and its data.
- **Remediation**:
  - **Never** construct shell commands by concatenating strings.
  - Use environment variables to pass data to scripts or use built-in node parameters where the tool handles sanitization.
  - If dynamic commands are unavoidable, implement a strict allow-list for characters and escape all shell metacharacters (e.g., `$` `( )` ` ` `;` `|` `&`) from all variables used in the command string.

### 2. SQL Injection in Multiple Workflows
- **Severity**: `CRITICAL`
- **Location**: `pentest_v4_cloud.json` & `credential_tester.json`
- **Description**: Multiple PostgreSQL nodes construct queries by embedding expressions (`{{ ... }}`) directly into the query string. This is classic string interpolation and is highly vulnerable to SQL Injection. While some inputs are cast to `::uuid`, others are strings that are not sanitized. The `Save Findings` node in the cloud workflow is particularly dangerous.
- **Example Vulnerable Code** (`pentest_v4_cloud.json` -> `Save Findings` node):
  ```sql
  -- The f.title, f.description, and f.remediation values are directly
  -- embedded in the query. A single quote in the title would break the
  -- query and allow an attacker to inject arbitrary SQL.
  INSERT INTO cloud_findings (title, description) VALUES (
    '${f.title.replace(/'/g, "''")}',
    '${(f.description || '').replace(/'/g, "''")}'
  );
  ```
  While an attempt is made to escape single quotes (`replace(/'/g, "''")`), this is not a robust solution and can be bypassed in complex scenarios. Other nodes do not even have this basic protection.
- **Impact**: Full database compromise, including data exfiltration, modification, and deletion. An attacker could potentially escalate this to RCE via database functions (`COPY ... FROM PROGRAM`).
- **Remediation**: Use parameterized queries. In n8n's PostgreSQL node, this is achieved by passing an array of values to the `Values` property in the node's options, and using placeholders like `$1`, `$2` in the query.

### 3. Insecure World-Writable Permissions in `Dockerfile`
- **Severity**: `CRITICAL`
- **Location**: `Dockerfile`
- **Description**: The Dockerfile sets world-writable permissions (`777`) on workspace directories.
  ```dockerfile
  RUN mkdir -p /opt/recon-workspace /opt/loot && \
      chmod -R 777 /opt/recon-workspace /opt/loot
  ```
- **Impact**: Any process or user within the container can write to these directories. If a low-privilege process is compromised, it can modify scripts, tools, or results in these folders, leading to further compromise or data tampering. This completely breaks process isolation.
- **Remediation**: Set more restrictive permissions. The directories should be owned by the `node` user and group, with permissions like `755` for directories and `644` for files.
  ```dockerfile
  RUN mkdir -p /opt/recon-workspace /opt/loot && \
      chown -R node:node /opt/recon-workspace /opt/loot && \
      chmod -R 755 /opt/recon-workspace /opt/loot
  ```

---

## HIGH Vulnerabilities

### 1. Discrepancy Between Documentation and Implementation
- **Severity**: `HIGH`
- **Location**: `README.md` vs. `pentest_v4_cloud.json`
- **Description**: The `README.md` extensively describes an AI-driven architecture where an LLM (`Ollama`) generates scan plans. However, the provided `pentest_v4_cloud.json` workflow contains entirely hardcoded logic in the `Build Cloud Commands` node, with a large `switch` statement for different scan modes. There is no call to any LLM.
- **Impact**: This is highly misleading. A user or auditor would assume AI-based dynamic planning, but the actual logic is static and predictable. This affects threat modeling, security expectations, and the ability to customize or extend the system as described.
- **Remediation**:
  - Update the `README.md` to accurately reflect the current hardcoded logic of the v4 cloud workflow.
  - Alternatively, implement the documented AI planner logic and remove the hardcoded `switch` statement.

### 2. Command Injection via Unsanitized `outputDir`
- **Severity**: `HIGH`
- **Location**: `pentest_v4_cloud.json` -> `Build Cloud Commands` node
- **Description**: The `outputDir` is constructed using `scanJobId`, which comes from the database. While less likely to be user-controlled, if an attacker could influence the `scanJobId` (e.g., via SQLi), they could inject characters into the `outputDir` path. This path is then used in multiple shell commands.
  ```javascript
  const outputDir = `/opt/recon-workspace/cloud_${scanJobId}`;
  commands.push(`mkdir -p ${outputDir}`);
  commands.push(`az ad user list --output json > ${outputDir}/users.json`);
  ```
- **Impact**: Potential for Remote Code Execution if `scanJobId` can be controlled.
- **Remediation**: Sanitize `scanJobId` before using it to construct the path. Ensure it conforms to an expected format (e.g., alphanumeric with dashes).

### 3. Plaintext Credentials on Command Line
- **Severity**: `HIGH`
- **Location**: `credential_tester.json` -> `Build Test Command` node
- **Description**: The workflow uses `sshpass -p 'PLACEHOLDER'` to supply a password for SSH authentication. This places the password directly on the command line.
- **Impact**: Any user or process on the system with sufficient permissions can view the running processes and their arguments (e.g., via `ps aux`), exposing the credential in plaintext.
- **Remediation**: Use more secure methods for authentication. For SSH, public key authentication is strongly preferred. If passwords must be used, leverage tools that can read the password from a file descriptor or standard input, rather than a command-line argument.

### 4. Race Condition (TOCTOU) in Rate Limiting
- **Severity**: `HIGH`
- **Location**: `pentest_v4_cloud.json` -> `Check Rate Limits` & `Create Scan Job` nodes
- **Description**: The workflow first `SELECT`s the current scan count to check against a limit, and then `INSERT`s a new scan job in a separate transaction. Two concurrent requests could both read a low count before either has a chance to insert, causing both to proceed and exceed the intended rate limit.
- **Impact**: The rate-limiting control can be bypassed, potentially leading to denial-of-service against target APIs or resource exhaustion on the n8n host.
- **Remediation**: Implement locking to make the check-and-insert operation atomic. Use a database-level lock (e.g., `SELECT ... FOR UPDATE`) or a distributed lock with Redis (`SETNX`) to ensure only one process can create a job at a time.

---

## MEDIUM Vulnerabilities

### 1. Use of `:latest` Tags in `Dockerfile`
- **Severity**: `MEDIUM`
- **Location**: `Dockerfile`
- **Description**: The `Dockerfile` uses `n8nio/n8n:latest` as its base image and installs Go tools using `@latest` or `@master`.
- **Impact**: This leads to non-deterministic builds. A future update to the base image or a tool could introduce breaking changes or new vulnerabilities without warning, making the system unstable and difficult to reproduce.
- **Remediation**: Pin all dependencies to specific versions or commit hashes (e.g., `n8nio/n8n:1.22.6`, `go install ...@v2.3.4`).

### 2. Missing Input Validation on Webhook
- **Severity**: `MEDIUM`
- **Location**: `pentest_v4_cloud.json` -> `Cloud Scan Webhook`
- **Description**: The webhook receives `project_id`, `credential_id`, `scan_mode`, and `tenant_id`. While `project_id` and `credential_id` are validated against the database, `scan_mode` and `tenant_id` are used directly. The `switch` statement for `scan_mode` has a `default`, which is good, but `tenant_id` is used in file paths and commands without validation.
- **Impact**: An invalid `tenant_id` could cause unexpected behavior or errors. An invalid `scan_mode` falls through to the default case, which may not be the desired behavior for a malformed input.
- **Remediation**: Add a validation step immediately after the webhook to check that all required inputs exist and conform to expected formats (e.g., `tenant_id` is a valid GUID, `scan_mode` is one of the allowed values).

### 3. Incomplete Error Handling for Executed Commands
- **Severity**: `MEDIUM`
- **Location**: `pentest_v4_cloud.json` -> `Execute Cloud Scans` node
- **Description**: The `Execute Cloud Scans` node joins many commands with `&&`. If any command in the middle of the chain fails, the entire chain stops, and the node fails. However, the workflow does not have a failure path from this node to update the `scan_jobs` table to a `failed` status. The job will remain in the `running` state indefinitely.
- **Impact**: Failed jobs are not correctly tracked, leading to orphaned "running" jobs in the database and a lack of visibility into scan failures.
- **Remediation**: Add a failure path from the `Execute Cloud Scans` node. Connect the "On Fail" output of the node to a new PostgreSQL node that updates the `scan_jobs` table status to `failed` and records the error message.

---

## LOW Vulnerabilities

### 1. Lack of Indexes on Foreign Keys in `007_phase_e_cloud.sql`
- **Severity**: `LOW`
- **Location**: `007_phase_e_cloud.sql`
- **Description**: The `azure_role_assignments` table has foreign key references to `azure_subscriptions(id)` and `azure_tenants(id)`, but there are no corresponding indexes on these columns (`subscription_id`, `tenant_id`).
- **Impact**: Queries that join `azure_role_assignments` with `azure_subscriptions` or `azure_tenants` will be inefficient and may cause performance degradation as the table grows.
- **Remediation**: Add indexes to the foreign key columns.
  ```sql
  CREATE INDEX idx_azure_role_assignments_subscription ON azure_role_assignments(subscription_id);
  CREATE INDEX idx_azure_role_assignments_tenant ON azure_role_assignments(tenant_id);
  ```

### 2. Potential for Duplicated Credential Tests
- **Severity**: `LOW`
- **Location**: `credential_tester.json`
- **Description**: The workflow runs on a 2-minute schedule and fetches 10 tests. If two workflow executions overlap, they could both fetch and run the same tests from the queue before they are marked as `processing`.
- **Impact**: Wasted resources and duplicated test results. The impact is low because the operations are mostly idempotent, but it is inefficient.
- **Remediation**: Use a `SELECT ... FOR UPDATE SKIP LOCKED` query in the `Get Queued Tests` node. This ensures that each worker process selects a distinct set of rows to work on, preventing overlap.

---

## Recommendations Summary

### Immediate Actions (Before Production)

1. **Fix Command Injection** - Sanitize all inputs used in shell commands
2. **Fix SQL Injection** - Use parameterized queries throughout
3. **Fix File Permissions** - Change 777 to appropriate restrictive permissions
4. **Update Documentation** - Clarify v4 cloud workflow uses hardcoded logic, not AI

### Short-Term Improvements

1. Implement atomic rate limiting with database locks
2. Add input validation for tenant_id and scan_mode
3. Add error handling paths for failed scans
4. Pin Docker image and tool versions

### Long-Term Enhancements

1. Implement proper secret management (HashiCorp Vault)
2. Add comprehensive logging and monitoring
3. Implement unit tests for workflow logic
4. Consider implementing AI planner for cloud scans
